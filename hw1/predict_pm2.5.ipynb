{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2655.2755680956516\n",
      "6.024929097538227\n",
      "6.026626776725642\n",
      "6.020821352808039\n",
      "5.862807444222179\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "from numpy import linalg as LA\n",
    "import csv\n",
    "\n",
    "def process_data(file_name, train_or_test):\n",
    "    if train_or_test == 'train':\n",
    "        data_file = open(file_name, 'r', encoding='big5')\n",
    "        raw_data = csv.reader(data_file)\n",
    "        raw_data = np.asarray(list(raw_data))\n",
    "        raw_data = np.delete(raw_data, 0, 0) # delete indexing(first row)\n",
    "        raw_data = np.delete(raw_data, np.s_[0:3:], 1) # delete date, location, entry_name(first three column)\n",
    "        np.place(raw_data, raw_data=='NR', '0') # replace NR with 0\n",
    "        raw_data = raw_data.astype(float) #to float data\n",
    "        \n",
    "        # transfer raw_data into data(every hour is a data)\n",
    "        data = []\n",
    "        shape = raw_data.shape\n",
    "        for row_ in range(shape[0]//18):\n",
    "            for col in range(shape[1]):\n",
    "                row = row_*18\n",
    "                tmp = raw_data[row:row+18, col]\n",
    "                data.append(tmp)\n",
    "        data = np.array(data)\n",
    "        \n",
    "    elif train_or_test == 'test':\n",
    "        data_file = open(file_name, 'r', encoding='big5')\n",
    "        raw_data = csv.reader(data_file)\n",
    "        raw_data = np.asarray(list(raw_data))\n",
    "        raw_data = np.delete(raw_data, np.s_[0:2:], 1)\n",
    "        np.place(raw_data, raw_data=='NR', '0') # replace NR with 0\n",
    "        raw_data = raw_data.astype(float) #to float data\n",
    "        \n",
    "        # transfer raw_data into data(every hour is a data)\n",
    "        data = []\n",
    "        shape = raw_data.shape\n",
    "        for row_ in range(shape[0]//18):\n",
    "            row = row_ * 18\n",
    "            tmp = raw_data[row:row+18,]\n",
    "            data.append(tmp.transpose().flatten())\n",
    "        data = np.array(data)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "#random choose 9 continous data, flatten it into a x\n",
    "#data[N][9] is the pm2.5 value of Nth data\n",
    "def choose_data(data, i):\n",
    "    x = data[i - 9:i,:].flatten()\n",
    "    y = data[i, 9]\n",
    "    return x, y\n",
    "    \n",
    "def regression(X_data, lr = 0.001, batch_size = 300, run = 100000, momentum_rate = 0.3):\n",
    "    W = np.random.rand(9*18).flatten() #initial random W\n",
    "    b = np.random.rand()\n",
    "    x_len = X_data.shape[0]\n",
    "    \n",
    "    b_lr = 0\n",
    "    w_lr = np.zeros(9*18).flatten()\n",
    "    dW = np.zeros(9*18).flatten()\n",
    "    db = 0\n",
    "    #batch SGD\n",
    "    for i in range(run):\n",
    "        #randon pick N data x, y_hat. N=batch_size\n",
    "        x = []\n",
    "        y_hat = []\n",
    "        for _ in range(batch_size):\n",
    "            n = np.random.randint(9, x_len) \n",
    "            xi, yi = choose_data(X_data, n)\n",
    "            x.append(xi)\n",
    "            y_hat.append(yi)\n",
    "        x = np.array(x)\n",
    "        y_hat = np.array(y_hat)\n",
    "        #calculate error\n",
    "        error = y_hat - (np.dot(x, W) + b) #nparray(batch_size, 1)\n",
    "        \n",
    "        #calculate gradient\n",
    "        dW = momentum_rate * dW + (1-momentum_rate)*(-2 * np.matmul(error, x))\n",
    "        db = momentum_rate * db + (1-momentum_rate)*(-2 * np.mean(error))\n",
    "        \n",
    "        #adagrad\n",
    "        b_lr = b_lr + db**2\n",
    "        w_lr = w_lr + dW**2\n",
    "        W = W - lr/np.sqrt(w_lr) * dW\n",
    "        b = b - lr/np.sqrt(b_lr) * db\n",
    "        \n",
    "        # random pick 10000 data for validation\n",
    "        if(i % 10000 == 0):\n",
    "            x = []\n",
    "            y_ = []\n",
    "            for _ in range(50000):\n",
    "                n = np.random.randint(9, x_len) \n",
    "                xi, yi = choose_data(X_data, n)\n",
    "                x.append(xi)\n",
    "                y_.append(yi)\n",
    "            x = np.array(x)\n",
    "            y_ = np.array(y_)\n",
    "            #calculate error\n",
    "            z = np.matmul(x, W) + b\n",
    "            error = y_ - (np.matmul(x, W) + b) #nparray(batch_size, 1)\n",
    "            loss = np.mean(np.square(error))\n",
    "            print(np.sqrt(loss))\n",
    "    \n",
    "    return W, b\n",
    "        \n",
    "def output_test(test_X, W, b):\n",
    "    Y = []\n",
    "    for x in test_X:\n",
    "        Y.append(np.dot(W, x) + b)\n",
    "    with open('ans.csv', 'w') as f:\n",
    "        f.write('id, value\\n')\n",
    "        for i, y in enumerate(Y):\n",
    "            f.write('id_' + str(i) + ',' + str(y) + '\\n')\n",
    "    \n",
    "data = process_data('train.csv', 'train')\n",
    "test_x = process_data('test_X.csv', 'test')\n",
    "W, b = regression(data, lr = 1, batch_size = 150, run = 50000)\n",
    "output_test(test_x, W, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
